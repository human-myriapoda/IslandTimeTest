{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import geemap\n",
    "import ee\n",
    "import os\n",
    "import pandas as pd\n",
    "from coastsat.coastsat import SDS_download, SDS_preprocess, SDS_shoreline, SDS_tools, SDS_transects\n",
    "import shapely\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import norm, gamma, f, chi2\n",
    "import IPython.display as disp\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel\n",
    "polygon = [[[166.908527, -0.539382],\n",
    "            [166.908527, -0.542476],\n",
    "            [166.912789, -0.542476],\n",
    "            [166.912789, -0.539382],\n",
    "            [166.908527, -0.539382]]]\n",
    "\n",
    "# Airport\n",
    "polygon_airport = [[[166.908527, -0.536727],\n",
    "            [166.908527, -0.558934],\n",
    "            [166.928538, -0.558934],\n",
    "            [166.928538, -0.536727],\n",
    "            [166.908527, -0.536727]]]\n",
    "\n",
    "polygon_coast = [[[166.905418, -0.528960], \n",
    "            [166.905418, -0.540194],\n",
    "            [166.915109, -0.540194],\n",
    "            [166.915109, -0.528960],\n",
    "            [166.905418, -0.528960]]]\n",
    "\n",
    "polygon_Maldives = [[[73.479003, 0.610048], \n",
    "            [73.479003, 0.598734],\n",
    "            [73.493267, 0.598734],\n",
    "            [73.493267, 0.610048],\n",
    "            [73.479003, 0.610048]]]\n",
    "\n",
    "polygon_gee = ee.Geometry.Polygon(polygon_Maldives) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images available between 2013-01-01 and 2023-12-31:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "     L8: 297 images\n",
      "     L9: 43 images\n",
      "     S2: 434 images\n",
      "  Total to download: 774 images\n",
      "- In Landsat Tier 2 (not suitable for time-series analysis):\n",
      "     L8: 111 images\n",
      "  Total Tier 2: 111 images\n"
     ]
    }
   ],
   "source": [
    "# date range\n",
    "dates = ['2013-01-01', '2023-12-31']\n",
    "\n",
    "# satellite missions \n",
    "sat_list = ['L5','L7','L8','L9','S2']\n",
    "sat_list = ['L8', 'L9', 'S2']\n",
    "\n",
    "# choose Landsat collection 'C01' or 'C02'\n",
    "collection = 'C02'\n",
    "\n",
    "# name of the site\n",
    "sitename = 'Vodamulaa_Maldives_2013_2023'\n",
    "\n",
    "# directory where the data will be stored\n",
    "filepath = os.path.join(os.getcwd(), 'data\\\\coastsat')\n",
    "\n",
    "# put all the inputs into a dictionnary\n",
    "inputs = {'polygon': polygon_Maldives, 'dates': dates, 'sat_list': sat_list, 'sitename': sitename, 'filepath': filepath,\n",
    "         'landsat_collection': collection}\n",
    "\n",
    "# before downloading the images, check how many images are available for your inputs\n",
    "SDS_download.check_images_available(inputs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = { \n",
    "    # general parameters:\n",
    "    'cloud_thresh': 0.5,        # threshold on maximum cloud cover\n",
    "    'dist_clouds': 50,         # ditance around clouds where shoreline can't be mapped\n",
    "    'output_epsg': 32643,       # epsg code of spatial reference system desired for the output\n",
    "    # quality control:\n",
    "    'check_detection': False,    # if True, shows each shoreline detection to the user for validation\n",
    "    'adjust_detection': False,  # if True, allows user to adjust the postion of each shoreline by changing the threhold\n",
    "    'save_figure': True,        # if True, saves a figure showing the mapped shoreline for each image\n",
    "    # [ONLY FOR ADVANCED USERS] shoreline detection parameters:\n",
    "    'min_beach_area': 0,     # minimum area (in metres^2) for an object to be labelled as a beach\n",
    "    'min_length_sl': 0,       # minimum length (in metres) of shoreline perimeter to be valid\n",
    "    'cloud_mask_issue': True,  # switch this parameter to True if sand pixels are masked (in black) on many images  \n",
    "    'sand_color': 'default',    # 'default', 'latest', 'dark' (for grey/black sand beaches) or 'bright' (for white sand beaches)\n",
    "    'pan_off': False,           # True to switch pansharpening off for Landsat 7/8/9 imagery\n",
    "    # add the inputs defined previously\n",
    "    'inputs': inputs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = SDS_download.get_metadata(inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images as jpg:\n",
      "L8: 296 images\n",
      "100%\n",
      "L9: 42 images\n",
      "100%\n",
      "S2: 433 images\n",
      "92%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\coastsat\\coastsat\\SDS_preprocess.py:534: UserWarning: c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\data\\coastsat\\Vodamulaa_Maldives_2013_2023\\jpg_files\\preprocessed\\RGB\\2022-11-07-05-38-50_RGB_S2.jpg is a low contrast image\n",
      "  imsave(fname, im_RGB, quality=100)\n",
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\coastsat\\coastsat\\SDS_preprocess.py:534: UserWarning: c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\data\\coastsat\\Vodamulaa_Maldives_2013_2023\\jpg_files\\preprocessed\\RGB\\2022-11-07-05-38-56_RGB_S2.jpg is a low contrast image\n",
      "  imsave(fname, im_RGB, quality=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%\n",
      "Satellite images saved as .jpg in c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\data\\coastsat\\Vodamulaa_Maldives_2013_2023\\jpg_files\\preprocessed\n"
     ]
    }
   ],
   "source": [
    "SDS_preprocess.save_jpg(metadata, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images available between 2013-01-01 and 2023-12-31:\n",
      "- In Landsat Tier 1 & Sentinel-2 Level-1C:\n",
      "     L8: 296 images\n",
      "     L9: 42 images\n",
      "     S2: 433 images\n",
      "  Total to download: 771 images\n",
      "- In Landsat Tier 2 (not suitable for time-series analysis):\n",
      "     L8: 110 images\n",
      "  Total Tier 2: 110 images\n",
      "\n",
      "Downloading images:\n",
      "L8: 296 images\n",
      "100%\n",
      "L9: 42 images\n",
      "100%\n",
      "S2: 433 images\n",
      "100%\n",
      "Satellite images downloaded from GEE and save in c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\data\\coastsat\\Vodamulaa_Maldives_2013_2023\n"
     ]
    }
   ],
   "source": [
    "metadata = SDS_download.retrieve_images(inputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference shoreline already exists and was loaded\n",
      "Reference shoreline coordinates are in epsg:32643\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "settings['reference_shoreline'] = SDS_preprocess.get_reference_sl(metadata, settings)\n",
    "settings['max_dist_ref'] = 25 # max distance (in meters) allowed from the reference shoreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping shorelines:\n",
      "L8:   1%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L8:   92%Could not map shoreline for this image: 2022-05-31-05-20-37_L8_Vodamulaa_Maldives_2013_2023_ms.tif\n",
      "L8:   100%\n",
      "L9:   2%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L9:   100%\n",
      "S2:   0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.2.post1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2:   100%\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "output = SDS_shoreline.extract_shorelines(metadata, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 duplicates\n",
      "17 bad georef\n"
     ]
    }
   ],
   "source": [
    "output = SDS_tools.remove_duplicates(output) # removes duplicates (images taken on the same date by the same satellite)\n",
    "output = SDS_tools.remove_inaccurate_georef(output, 10) # remove inaccurate georeferencing (set threshold to 10 m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS\n",
    "geomtype = 'points' # choose 'points' or 'lines' for the layer geometry\n",
    "gdf = SDS_tools.output_to_gdf(output, geomtype)\n",
    "if gdf is None:\n",
    "    raise Exception(\"output does not contain any mapped shorelines\")\n",
    "gdf.crs = CRS(settings['output_epsg']) # set layer projection\n",
    "# save GEOJSON layer to file\n",
    "gdf.to_file(os.path.join(inputs['filepath'], inputs['sitename'], '%s_output_%s.geojson'%(sitename,geomtype)),\n",
    "                                driver='GeoJSON', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\case_study_Nauru.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(sl[:,\u001b[39m0\u001b[39m], sl[:,\u001b[39m1\u001b[39m], \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39mdate\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m plt\u001b[39m.\u001b[39;49mshow();\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\matplotlib\\backend_bases.py:3620\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3618\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3619\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m-> 3620\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\matplotlib\\backends\\backend_qt.py:605\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m qapp:\n\u001b[0;32m    604\u001b[0m     \u001b[39mwith\u001b[39;00m _maybe_allow_interrupt(qapp):\n\u001b[1;32m--> 605\u001b[0m         qt_compat\u001b[39m.\u001b[39m_exec(qapp)\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\contextlib.py:120\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    121\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\matplotlib\\backends\\qt_compat.py:245\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    243\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m handler_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     old_sigint_handler(\u001b[39m*\u001b[39;49mhandler_args)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=[15,8])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output['shorelines'])):\n",
    "    sl = output['shorelines'][i]\n",
    "    date = output['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.', label=date.strftime('%d-%m-%Y'))\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 duplicates\n",
      "17 bad georef\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(inputs['filepath'], sitename)\n",
    "with open(os.path.join(filepath, sitename + '_output' + '.pkl'), 'rb') as f:\n",
    "    output = pickle.load(f)\n",
    "# remove duplicates (images taken on the same date by the same satellite)\n",
    "output = SDS_tools.remove_duplicates(output)\n",
    "# remove inaccurate georeferencing (set threshold to 10 m)\n",
    "output = SDS_tools.remove_inaccurate_georef(output, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 transects have been loaded coordinates are in epsg:4326\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "#transects = SDS_transects.draw_transects(output, settings)\n",
    "geojson_file = os.path.join(os.getcwd(), 'data\\\\coastsat\\\\Vodamulaa_Maldives_2013_2023', 'Vodamulaa_Maldives_2013_2023_transects.geojson')\n",
    "transects = SDS_tools.transects_from_geojson(geojson_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Eastings')\n",
    "plt.ylabel('Northings')\n",
    "plt.grid(linestyle=':', color='0.5')\n",
    "for i in range(len(output['shorelines'])):\n",
    "    sl = output['shorelines'][i]\n",
    "    date = output['dates'][i]\n",
    "    plt.plot(sl[:,0], sl[:,1], '.', label=date.strftime('%d-%m-%Y'))\n",
    "for i,key in enumerate(list(transects.keys())):\n",
    "    plt.plot(transects[key][0,0],transects[key][0,1], 'bo', ms=5)\n",
    "    plt.plot(transects[key][:,0],transects[key][:,1],'k-',lw=1)\n",
    "    plt.text(transects[key][0,0]-100, transects[key][0,1]+100, key,\n",
    "                va='center', ha='right', bbox=dict(boxstyle=\"square\", ec='k',fc='w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# along-shore distance over which to consider shoreline points to compute the median intersection\n",
    "settings_transects = {'along_dist':25}\n",
    "cross_distance = SDS_transects.compute_intersection(output, transects, settings_transects) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1217: RuntimeWarning: All-NaN slice encountered\n",
      "  return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n",
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\coastsat\\coastsat\\SDS_transects.py:337: RuntimeWarning: All-NaN slice encountered\n",
      "  max_intersect[i] = np.nanmax(xy_rot[0,:])\n",
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\coastsat\\coastsat\\SDS_transects.py:338: RuntimeWarning: All-NaN slice encountered\n",
      "  min_intersect[i] = np.nanmin(xy_rot[0,:])\n"
     ]
    }
   ],
   "source": [
    "settings_transects = { # parameters for computing intersections\n",
    "                      'along_dist':          25,        # along-shore distance to use for computing the intersection\n",
    "                      'min_points':          3,         # minimum number of shoreline points to calculate an intersection\n",
    "                      'max_std':             15,        # max std for points around transect\n",
    "                      'max_range':           30,        # max range for points around transect\n",
    "                      'min_chainage':        -100,      # largest negative value along transect (landwards of transect origin)\n",
    "                      'multiple_inter':      'auto',    # mode for removing outliers ('auto', 'nan', 'max')\n",
    "                      'prc_multiple':         0.1,      # percentage of the time that multiple intersects are present to use the max\n",
    "                     }\n",
    "cross_distance = SDS_transects.compute_intersection_QC(output, transects, settings_transects) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\anaconda3\\envs\\coastsatn\\lib\\site-packages\\ipykernel\\eventloops.py:128: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  el.exec() if hasattr(el, 'exec') else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "gs = gridspec.GridSpec(len(cross_distance),1)\n",
    "gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.05)\n",
    "for i,key in enumerate(cross_distance.keys()):\n",
    "    if np.all(np.isnan(cross_distance[key])):\n",
    "        continue\n",
    "    ax = fig.add_subplot(gs[i,0])\n",
    "    ax.grid(linestyle=':', color='0.5')\n",
    "    ax.set_ylim([-50,50])\n",
    "    ax.plot(output['dates'], cross_distance[key]- np.nanmedian(cross_distance[key]), '-o', ms=6, mfc='w')\n",
    "    ax.set_ylabel('distance [m]', fontsize=12)\n",
    "    ax.text(0.5,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',\n",
    "            va='top', transform=ax.transAxes, fontsize=14)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series of the shoreline change along the transects saved as:\n",
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\data\\coastsat\\Vodamulaa_Maldives_2013_2023\\transect_time_series_May29.csv\n"
     ]
    }
   ],
   "source": [
    "# save a .csv file for Excel users\n",
    "out_dict = dict([])\n",
    "out_dict['dates'] = output['dates']\n",
    "for key in transects.keys():\n",
    "    out_dict[key] = cross_distance[key]\n",
    "df = pd.DataFrame(out_dict)\n",
    "fn = os.path.join(settings['inputs']['filepath'],settings['inputs']['sitename'],\n",
    "                  'transect_time_series_May29.csv')\n",
    "df.to_csv(fn, sep=',')\n",
    "print('Time-series of the shoreline change along the transects saved as:\\n%s'%fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  - outliers removed: 10\n",
      "2  - outliers removed: 10\n",
      "3  - outliers removed: 9\n",
      "4  - outliers removed: 10\n",
      "5  - outliers removed: 9\n",
      "6  - outliers removed: 10\n",
      "7  - outliers removed: 8\n",
      "8  - outliers removed: 8\n",
      "9  - outliers removed: 9\n",
      "10  - outliers removed: 10\n",
      "11  - outliers removed: 9\n",
      "12  - outliers removed: 9\n",
      "13  - outliers removed: 11\n",
      "14  - outliers removed: 10\n",
      "15  - outliers removed: 9\n",
      "16  - outliers removed: 9\n",
      "17  - outliers removed: 8\n",
      "18  - outliers removed: 8\n",
      "19  - outliers removed: 9\n",
      "20  - outliers removed: 9\n",
      "21  - outliers removed: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\coastsat\\coastsat\\SDS_transects.py:458: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig,ax=plt.subplots(2,1,figsize=[12,6], sharex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22  - outliers removed: 9\n",
      "23  - outliers removed: 9\n",
      "24  - outliers removed: 9\n",
      "25  - outliers removed: 9\n",
      "26  - outliers removed: 9\n",
      "27  - outliers removed: 9\n",
      "28  - outliers removed: 8\n",
      "29  - outliers removed: 9\n",
      "30  - outliers removed: 9\n",
      "31  - outliers removed: 10\n",
      "32  - outliers removed: 9\n",
      "33  - outliers removed: 12\n",
      "34  - outliers removed: 10\n",
      "35  - outliers removed: 9\n",
      "36  - outliers removed: 9\n",
      "37  - outliers removed: 10\n",
      "38  - outliers removed: 10\n",
      "39  - outliers removed: 8\n",
      "40  - outliers removed: 8\n",
      "41  - outliers removed: 10\n",
      "42  - outliers removed: 10\n",
      "43  - outliers removed: 10\n",
      "44  - outliers removed: 10\n",
      "45  - outliers removed: 10\n",
      "46  - outliers removed: 9\n",
      "47  - outliers removed: 10\n",
      "48  - outliers removed: 9\n",
      "49  - outliers removed: 10\n",
      "50  - outliers removed: 10\n",
      "51  - outliers removed: 8\n"
     ]
    }
   ],
   "source": [
    "# remove outliers in the time-series (coastal despiking)\n",
    "settings_outliers = {'max_cross_change':   40,             # maximum cross-shore change observable between consecutive timesteps\n",
    "                     'otsu_threshold':     [-.5,0],        # min and max intensity threshold use for contouring the shoreline\n",
    "                     'plot_fig':           True,           # whether to plot the intermediate steps\n",
    "                    }\n",
    "cross_distance = SDS_transects.reject_outliers(cross_distance,output,settings_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-series of the shoreline change along the transects saved as:\n",
      "c:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\data\\coastsat\\Vodamulaa_Maldives_2013_2023\\transect_time_series_corrected_29May.csv\n"
     ]
    }
   ],
   "source": [
    "# save a .csv file for Excel users\n",
    "out_dict = dict([])\n",
    "out_dict['dates'] = output['dates']\n",
    "for key in transects.keys():\n",
    "    out_dict[key] = cross_distance[key]\n",
    "df = pd.DataFrame(out_dict)\n",
    "fn = os.path.join(settings['inputs']['filepath'],settings['inputs']['sitename'],\n",
    "                  'transect_time_series_corrected_29May.csv')\n",
    "df.to_csv(fn, sep=',')\n",
    "print('Time-series of the shoreline change along the transects saved as:\\n%s'%fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\case_study_Nauru.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# remove nans\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m idx_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(chainage)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dates_nonan \u001b[39m=\u001b[39m [dates[_] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mwhere(\u001b[39m~\u001b[39midx_nan)[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chainage \u001b[39m=\u001b[39m chainage[\u001b[39m~\u001b[39midx_nan] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# compute shoreline seasonal averages (DJF, MAM, JJA, SON)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\case_study_Nauru.ipynb Cell 23\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# remove nans\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m idx_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(chainage)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dates_nonan \u001b[39m=\u001b[39m [dates[_] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mwhere(\u001b[39m~\u001b[39midx_nan)[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chainage \u001b[39m=\u001b[39m chainage[\u001b[39m~\u001b[39midx_nan] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# compute shoreline seasonal averages (DJF, MAM, JJA, SON)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "season_colors = {'DJF':'C3', 'MAM':'C1', 'JJA':'C2', 'SON':'C0'}\n",
    "for key in cross_distance.keys():\n",
    "    chainage = cross_distance[key]\n",
    "    # remove nans\n",
    "    idx_nan = np.isnan(chainage)\n",
    "    dates_nonan = [dates[_] for _ in np.where(~idx_nan)[0]]\n",
    "    chainage = chainage[~idx_nan] \n",
    "    \n",
    "    # compute shoreline seasonal averages (DJF, MAM, JJA, SON)\n",
    "    dict_seas, dates_seas, chainage_seas, list_seas = SDS_transects.seasonal_average(dates_nonan, chainage)\n",
    "    \n",
    "    # plot seasonal averages\n",
    "    fig,ax=plt.subplots(1,1,figsize=[14,4],tight_layout=True)\n",
    "    #ax.grid(b=True,which='major', linestyle=':', color='0.5')\n",
    "    ax.set_title('Time-series at %s'%key, x=0, ha='left')\n",
    "    ax.set(ylabel='distance [m]')\n",
    "    ax.plot(dates_nonan, chainage,'+', lw=1, color='k', mfc='w', ms=4, alpha=0.5,label='raw datapoints')\n",
    "    ax.plot(dates_seas, chainage_seas, '-', lw=1, color='k', mfc='w', ms=4, label='seasonally-averaged')\n",
    "    for k,seas in enumerate(dict_seas.keys()):\n",
    "        ax.plot(dict_seas[seas]['dates'], dict_seas[seas]['chainages'],\n",
    "                 'o', mec='k', color=season_colors[seas], label=seas,ms=5)\n",
    "    ax.legend(loc='lower left',ncol=6,markerscale=1.5,frameon=True,edgecolor='k',columnspacing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myriampe\\AppData\\Local\\Temp\\ipykernel_23172\\1729604929.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  month_colors = plt.cm.get_cmap('tab20')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\case_study_Nauru.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# remove nans\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m idx_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(chainage)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dates_nonan \u001b[39m=\u001b[39m [dates[_] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mwhere(\u001b[39m~\u001b[39midx_nan)[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chainage \u001b[39m=\u001b[39m chainage[\u001b[39m~\u001b[39midx_nan] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# compute shoreline monthly averages\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\myriampe\\OneDrive\\Documents\\PhD in Earth Science\\Projects\\Islands-CI\\case_study_Nauru.ipynb Cell 24\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# remove nans\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m idx_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(chainage)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dates_nonan \u001b[39m=\u001b[39m [dates[_] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mwhere(\u001b[39m~\u001b[39midx_nan)[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m chainage \u001b[39m=\u001b[39m chainage[\u001b[39m~\u001b[39midx_nan] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/myriampe/OneDrive/Documents/PhD%20in%20Earth%20Science/Projects/Islands-CI/case_study_Nauru.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# compute shoreline monthly averages\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "month_colors = plt.cm.get_cmap('tab20')\n",
    "for key in cross_distance.keys():\n",
    "    chainage = cross_distance[key]\n",
    "    # remove nans\n",
    "    idx_nan = np.isnan(chainage)\n",
    "    dates_nonan = [dates[_] for _ in np.where(~idx_nan)[0]]\n",
    "    chainage = chainage[~idx_nan] \n",
    "    \n",
    "    # compute shoreline monthly averages\n",
    "    dict_month, dates_month, chainage_month, list_month = SDS_transects.monthly_average(dates_nonan, chainage)\n",
    "    \n",
    "    # plot monthly averages\n",
    "    fig,ax=plt.subplots(1,1,figsize=[14,4],tight_layout=True)\n",
    "    #ax.grid(b=True,which='major', linestyle=':', color='0.5')\n",
    "    ax.set_title('Time-series at %s'%key, x=0, ha='left')\n",
    "    ax.set(ylabel='distance [m]')\n",
    "    ax.plot(dates_nonan, chainage,'+', lw=1, color='k', mfc='w', ms=4, alpha=0.5,label='raw datapoints')\n",
    "    ax.plot(dates_month, chainage_month, '-', lw=1, color='k', mfc='w', ms=4, label='monthly-averaged')\n",
    "    for k,month in enumerate(dict_month.keys()):\n",
    "        ax.plot(dict_month[month]['dates'], dict_month[month]['chainages'],\n",
    "                 'o', mec='k', color=month_colors(k), label=month,ms=5)\n",
    "    ax.legend(loc='lower left',ncol=7,markerscale=1.5,frameon=True,edgecolor='k',columnspacing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = pd.read_csv(os.getcwd()+'\\\\data\\\\coastsat\\\\Vodamulaa_Maldives_2013_2023\\\\transect_time_series_corrected_29May.csv')\n",
    "plt.figure()\n",
    "plt.plot(timeseries.dates, timeseries['18'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2013, 12, 16, 5, 22, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2014, 2, 2, 5, 21, 17, tzinfo=<UTC>),\n",
       " datetime.datetime(2014, 3, 6, 5, 20, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2014, 4, 7, 5, 20, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2014, 6, 26, 5, 20, 20, tzinfo=<UTC>),\n",
       " datetime.datetime(2014, 11, 17, 5, 20, 26, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 2, 5, 5, 20, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 3, 9, 5, 19, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 3, 25, 5, 19, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 4, 10, 5, 19, 36, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 5, 28, 5, 19, 42, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 6, 13, 5, 19, 30, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 8, 16, 5, 37, 6, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 8, 16, 5, 37, 6, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 9, 5, 5, 37, 7, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 9, 17, 5, 20, 35, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 10, 3, 5, 20, 39, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 10, 5, 5, 37, 8, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 11, 20, 5, 20, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 12, 4, 5, 37, 6, tzinfo=<UTC>),\n",
       " datetime.datetime(2015, 12, 22, 5, 20, 23, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 1, 3, 5, 39, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 1, 23, 5, 20, 43, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 1, 23, 5, 39, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 2, 8, 5, 20, 38, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 2, 12, 5, 37, 2, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 2, 24, 5, 20, 8, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 3, 11, 5, 20, 6, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 3, 23, 5, 32, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 3, 27, 5, 20, 20, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 4, 12, 5, 19, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 4, 12, 5, 37, 15, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 4, 28, 5, 20, 12, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 5, 2, 5, 37, 20, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 5, 30, 5, 19, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 6, 11, 5, 37, 19, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 7, 1, 5, 20, 5, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 7, 1, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 8, 10, 5, 37, 19, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 9, 29, 5, 37, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 10, 29, 5, 37, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 11, 8, 5, 37, 14, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 11, 28, 5, 37, 14, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 12, 8, 5, 20, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 12, 8, 5, 37, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2016, 12, 18, 5, 37, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 1, 7, 5, 37, 5, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 1, 9, 5, 20, 25, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 1, 25, 5, 20, 44, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 1, 27, 5, 37, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 2, 10, 5, 20, 35, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 3, 8, 5, 37, 8, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 3, 18, 5, 37, 7, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 3, 28, 5, 37, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 3, 30, 5, 19, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 4, 7, 5, 37, 14, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 4, 17, 5, 37, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 4, 27, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 5, 17, 5, 37, 19, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 6, 6, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 6, 16, 5, 37, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 6, 18, 5, 20, 21, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 7, 1, 5, 37, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 7, 11, 5, 37, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 7, 16, 5, 37, 17, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 7, 26, 5, 37, 17, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 8, 5, 5, 20, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 8, 5, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 8, 20, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 8, 30, 5, 37, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 9, 14, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 9, 29, 5, 37, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 8, 5, 20, 30, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 9, 5, 37, 1, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 14, 5, 37, 15, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 19, 5, 37, 2, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 24, 5, 20, 32, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 24, 5, 37, 33, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 10, 29, 5, 37, 3, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 11, 13, 5, 37, 14, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 11, 25, 5, 20, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 12, 8, 5, 37, 4, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 12, 13, 5, 37, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2017, 12, 23, 5, 37, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 1, 2, 5, 37, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 1, 12, 5, 37, 8, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 1, 28, 5, 20, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 2, 1, 5, 37, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 2, 6, 5, 37, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 2, 11, 5, 37, 12, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 3, 1, 5, 20, 20, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 3, 13, 5, 37, 12, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 3, 17, 5, 20, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 3, 18, 5, 37, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 4, 2, 5, 19, 40, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 4, 2, 5, 37, 15, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 4, 7, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 4, 22, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 5, 2, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 5, 12, 5, 37, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 5, 17, 5, 37, 14, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 6, 21, 5, 19, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 6, 21, 5, 37, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 7, 1, 5, 38, 29, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 7, 26, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 8, 5, 5, 37, 12, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 8, 10, 5, 37, 16, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 9, 9, 5, 20, 14, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 9, 9, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 9, 14, 5, 37, 7, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 9, 24, 5, 38, 32, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 9, 29, 5, 37, 12, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 10, 4, 5, 37, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 10, 14, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 10, 24, 5, 37, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 11, 12, 5, 20, 34, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 11, 18, 5, 38, 44, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 11, 23, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 11, 28, 5, 38, 42, tzinfo=<UTC>),\n",
       " datetime.datetime(2018, 12, 28, 5, 38, 44, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 1, 15, 5, 20, 4, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 1, 22, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 1, 27, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 2, 6, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 2, 11, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 2, 16, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 2, 21, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 3, 8, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 3, 13, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 3, 18, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 3, 20, 5, 20, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 3, 23, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 4, 5, 5, 19, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 4, 7, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 4, 12, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 4, 22, 5, 38, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 5, 2, 5, 38, 58, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 5, 7, 5, 19, 43, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 5, 7, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 5, 12, 5, 38, 59, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 5, 17, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 6, 6, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 6, 21, 5, 38, 59, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 6, 24, 5, 20, 6, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 7, 1, 5, 38, 59, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 7, 6, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 7, 10, 5, 20, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 7, 26, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 7, 31, 5, 38, 59, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 8, 20, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 9, 4, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 10, 4, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 11, 3, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 11, 13, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 11, 18, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 11, 23, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 12, 1, 5, 20, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 12, 3, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2019, 12, 17, 5, 20, 31, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 1, 2, 5, 20, 27, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 1, 2, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 1, 7, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 1, 12, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 1, 22, 5, 38, 44, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 2, 1, 5, 38, 43, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 2, 3, 5, 20, 18, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 2, 6, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 2, 11, 5, 38, 43, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 3, 2, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 3, 7, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 3, 12, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 3, 17, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 3, 22, 5, 20, 2, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 3, 22, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 4, 6, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 4, 7, 5, 20, 17, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 4, 11, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 4, 26, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 5, 9, 5, 19, 37, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 5, 16, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 5, 21, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 5, 31, 5, 38, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 6, 5, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 6, 10, 5, 19, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 6, 10, 5, 38, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 6, 26, 5, 20, 22, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 6, 30, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 7, 5, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 7, 10, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 7, 12, 5, 20, 5, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 7, 15, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 7, 28, 5, 20, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 8, 4, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 8, 9, 5, 38, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 8, 14, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 8, 19, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 9, 3, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 9, 8, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 9, 14, 5, 20, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 9, 23, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 9, 28, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 10, 18, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 10, 28, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 11, 7, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 11, 22, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 12, 3, 5, 20, 59, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 12, 7, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 12, 12, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 12, 17, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 12, 19, 5, 20, 34, tzinfo=<UTC>),\n",
       " datetime.datetime(2020, 12, 27, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 1, 4, 5, 20, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 1, 6, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 1, 16, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 1, 21, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 2, 5, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 2, 10, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 2, 20, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 3, 2, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 3, 7, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 3, 12, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 3, 17, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 3, 22, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 4, 6, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 4, 11, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 4, 16, 5, 38, 42, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 4, 21, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 4, 26, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 5, 1, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 5, 21, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 6, 10, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 6, 15, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 7, 15, 5, 20, 9, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 8, 14, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 8, 19, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 9, 3, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 9, 13, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 10, 3, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 10, 8, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 10, 28, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 11, 2, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 11, 7, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 11, 12, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 11, 13, 5, 19, 32, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 11, 17, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 11, 27, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 12, 7, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 12, 27, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 1, 1, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 1, 6, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 1, 7, 5, 20, 29, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 1, 31, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 2, 5, 5, 38, 45, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 2, 10, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 2, 15, 5, 38, 44, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 2, 20, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 2, 24, 5, 20, 40, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 2, 25, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 2, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 4, 5, 20, 15, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 7, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 12, 5, 20, 12, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 12, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 17, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 22, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 3, 27, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 1, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 6, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 11, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 13, 5, 20, 28, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 16, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 21, 5, 20, 23, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 21, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 4, 26, 5, 38, 44, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 5, 6, 5, 38, 46, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 5, 16, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 5, 21, 5, 38, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 5, 26, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 5, 31, 5, 38, 58, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 6, 5, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 6, 10, 5, 39, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 6, 15, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 7, 5, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 7, 25, 5, 38, 56, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 7, 26, 5, 20, 13, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 8, 14, 5, 38, 54, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 8, 19, 5, 21, 10, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 8, 19, 5, 39, 3, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 8, 24, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 8, 29, 5, 39, 3, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 9, 3, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 9, 8, 5, 39, 2, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 9, 12, 5, 20, 30, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 9, 13, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 9, 18, 5, 38, 59, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 9, 23, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 10, 3, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 10, 8, 5, 38, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 10, 18, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 10, 23, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 11, 12, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 11, 17, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 11, 22, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 11, 27, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 12, 2, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 12, 7, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 12, 25, 5, 20, 37, tzinfo=<UTC>),\n",
       " datetime.datetime(2022, 12, 27, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 1, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 6, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 16, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 21, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 26, 5, 20, 36, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 26, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 1, 31, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 3, 5, 21, 7, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 5, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 10, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 11, 5, 20, 57, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 15, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 20, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 2, 25, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 3, 2, 5, 38, 51, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 3, 7, 5, 20, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 3, 7, 5, 38, 47, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 3, 12, 5, 38, 55, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 3, 17, 5, 38, 48, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 3, 27, 5, 38, 49, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 4, 6, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 4, 11, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 4, 16, 5, 20, 11, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 4, 21, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 4, 24, 5, 20, 4, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 4, 26, 5, 38, 50, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 5, 10, 5, 19, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 5, 11, 5, 38, 53, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 5, 16, 5, 38, 52, tzinfo=<UTC>),\n",
       " datetime.datetime(2023, 5, 21, 5, 38, 56, tzinfo=<UTC>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in cross_distance.keys():\n",
    "    chainage = cross_distance[key]\n",
    "    # remove nans\n",
    "    idx_nan = np.isnan(chainage)\n",
    "    dates_nonan = [dates[_] for _ in np.where(~idx_nan)[0]]\n",
    "    chainage = chainage[~idx_nan] \n",
    "\n",
    "plt.plot(dates_nonan, chainage)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islands-db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
